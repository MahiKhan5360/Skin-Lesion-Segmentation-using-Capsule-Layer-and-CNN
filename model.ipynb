{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahiKhan5360/Skin-Lesion-Segmentation-using-Capsule-Layer-and-CNN/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOrnHpBqJcWf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, UpSampling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Capsule Layer Class\n",
        "def create_capsule_layer():\n",
        "    class CapsuleLayer(tf.keras.layers.Layer):\n",
        "        def __init__(self, num_capsules=4, capsule_dim=8, num_routing=2, **kwargs):\n",
        "            super(CapsuleLayer, self).__init__(**kwargs)\n",
        "            self.num_capsules = num_capsules\n",
        "            self.capsule_dim = capsule_dim\n",
        "            self.num_routing = num_routing\n",
        "\n",
        "        def build(self, input_shape):\n",
        "            self.input_channels = input_shape[-1]\n",
        "\n",
        "            self.W = self.add_weight(\n",
        "                shape=[self.input_channels, self.num_capsules * self.capsule_dim],\n",
        "                initializer='glorot_uniform',\n",
        "                trainable=True\n",
        "            )\n",
        "            super().build(input_shape)\n",
        "\n",
        "        def compute_output_shape(self, input_shape):\n",
        "\n",
        "            return (input_shape[0], input_shape[1], input_shape[2], self.capsule_dim)\n",
        "\n",
        "        def call(self, inputs):\n",
        "            batch_size = tf.shape(inputs)[0]\n",
        "            height, width = inputs.shape[1], inputs.shape[2]\n",
        "\n",
        "            inputs_activated = tf.nn.relu(inputs)\n",
        "\n",
        "\n",
        "            u_hat = tf.matmul(\n",
        "                tf.reshape(inputs_activated, [-1, self.input_channels]),\n",
        "                self.W\n",
        "            )\n",
        "            u_hat = tf.reshape(u_hat, [batch_size, height, width, self.num_capsules, self.capsule_dim])\n",
        "\n",
        "\n",
        "            b = tf.zeros([batch_size, height, width, self.num_capsules])\n",
        "\n",
        "            for i in range(self.num_routing):\n",
        "                # Softmax over capsules dimension\n",
        "                c = tf.nn.softmax(b, axis=-1)  # Shape: [batch, height, width, num_capsules]\n",
        "\n",
        "                # Expand c to match u_hat dimensions for element-wise multiplication\n",
        "                c_expanded = tf.expand_dims(c, axis=-1)  # Shape: [batch, height, width, num_capsules, 1]\n",
        "\n",
        "\n",
        "                s = tf.reduce_sum(c_expanded * u_hat, axis=3)  # Sum over num_capsules\n",
        "                # s shape: [batch, height, width, capsule_dim]\n",
        "\n",
        "                # Apply squashing\n",
        "                v = self.squash(s)\n",
        "\n",
        "                # Update routing coefficients if not last iteration\n",
        "                if i < self.num_routing - 1:\n",
        "                    # v shape: [batch, height, width, capsule_dim]\n",
        "                    # u_hat shape: [batch, height, width, num_capsules, capsule_dim]\n",
        "                    v_expanded = tf.expand_dims(v, axis=3)  # [batch, height, width, 1, capsule_dim]\n",
        "\n",
        "                    # Calculate agreement: dot product between v and each u_hat\n",
        "                    agreement = tf.reduce_sum(u_hat * v_expanded, axis=-1)  # [batch, height, width, num_capsules]\n",
        "                    b = b + agreement\n",
        "\n",
        "            return v\n",
        "\n",
        "        def squash(self, s, axis=-1, epsilon=1e-9):\n",
        "            s_squared_norm = tf.reduce_sum(tf.square(s), axis=axis, keepdims=True)\n",
        "            scale = s_squared_norm / (1 + s_squared_norm + epsilon)\n",
        "            return scale * s / tf.sqrt(s_squared_norm + epsilon)\n",
        "\n",
        "    return CapsuleLayer\n",
        "\n",
        "# Memory-efficient Model Creation\n",
        "def create_efficient_capsule_segmentation_model(input_shape=(256, 256, 3), num_capsules=4, capsule_dim=8):\n",
        "    CapsuleLayer = create_capsule_layer()\n",
        "\n",
        "    # Input layer\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "\n",
        "    # Encoder:\n",
        "    # Block 1\n",
        "    x = Conv2D(filters=32, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.0001))(input_layer)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(filters=32, kernel_size=3, activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.2)(x)  # Reduced dropout\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(filters=64, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.0001))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(filters=64, kernel_size=3, activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # Block 3 - Additional downsampling to reduce spatial dimension\n",
        "    x = Conv2D(filters=128, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.0001))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # Capsule layer with reduced parameters\n",
        "    x = CapsuleLayer(num_capsules=num_capsules, capsule_dim=capsule_dim)(x)\n"
      ],
      "metadata": {
        "id": "TyEuCPzLJ0t0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}